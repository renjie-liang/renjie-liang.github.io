---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}


# About Me
<span class='anchor' id='about-me'></span>

I am Renjie Liang, a Ph.D. student at the University of Florida (UF), where I serve as a research assistant in the Health Outcomes & Biomedical Informatics (HOBI) department. My research interests focus on medical image report generation using Large Language Models (LLMs), particularly for 3D CT renal images. In addition, I am exploring out-of-distribution detection and improving efficiency in radiology image for report generation.
My goal is to develop amazing models with real-world data to reduce the tedious workload for medical scripting and improve its quality. Eventually, I hope to contribute to the advancement of medical report generation and improve healthcare outcomes for humanity.



# Work Experiences

<span class='anchor' id='work-experiences'></span>
<b>Research Assistant, HOBI, University of Florida</b>

<div style="text-align: right;">
    <b>2024. Aug - Present</b>
    <br/>
    Prof. <a href="https://hobi.med.ufl.edu/profile/xu-jie/" target="_blank">Jie Xu</a>
</div>

--- 
<b>Research Associate, S-Lab, Nanyang Technological University</b>

<div style="text-align: right;">
    <b>2023. Apr - 2024. Aug</b>
    <br/>
    Prof. <a href="https://scholar.google.com/citations?user=wyKGVKUAAAAJ&hl=zh-CN" target="_blank">Aixin Sun</a>
</div>

--- 
<b>Research Intern, NExT++, National University of Singapore</b>

<div style="text-align: right;">
    <b>2022. Mar - 2023. Apr</b>
    <br/>
    Prof. <a href="https://scholar.google.com/citations?user=Z9DWCBEAAAAJ&hl=zh-CN&oi=ao" target="_blank">Tat-Seng Chua</a>
    and Postdoc <a href="https://jiwei0523.github.io/" target="_blank">Wei Ji</a>
</div>


---

<b> Engineer, Bytedance </b>

<div style="text-align: right;">
    <br/>
   2020.Oct - 2021. Dec </b>
<br/>

  

         

<h2>Education</h2>
<span class='anchor' id='educations'></span>

<div>
  <p><strong>2024. Aug - Present</strong><br>
  <strong>Doctor of Philosophy in Biomedical Informatics</strong><br>
  University of Florida, USA</p>
</div>

<hr>

<div>
  <p><strong>2018. Sep - 2020. Jun</strong><br>
  <strong>Master of Engineering in Computer Science</strong><br>
  Sun Yat-sen University, China</p>
</div>

<hr>

<div>
  <p><strong>2013. Sep - 2017. Jun</strong><br>
  <strong>Bachelor of Engineering in Mining Engineering</strong><br>
  Central South University, China</p>
</div>


  
<!--
# Educations


- Supervised by Prof. [Jie Xu](https://hobi.med.ufl.edu/profile/xu-jie/)
- Research on AI for healthcare



<div style="display: flex; justify-content: space-between; align-items: center;">
    <span style="margin: 0; font-weight: bold;"></span>
    <span style="text-align: right; font-weight: bold;"> </span>
</div>


# Work Experiences
<span class='anchor' id='work-experiences'></span>

<div style="display: flex; justify-content: space-between; align-items: center; width: 100%;">
    <span style="margin: 0; font-weight: bold; flex-grow: 1;">2023. Apr - 2024. Aug</span>
    <span style="margin: 0; font-weight: bold; flex-grow: 1; text-align: right;">Research Associate, S-Lab, NTU</span>
</div>

- Supervised by Prof. [Aixin Sun](https://scholar.google.com/citations?user=wyKGVKUAAAAJ&hl=zh-CN)
- Proposed a novel task, Ranked Video Moment Retrieval, and curated the TVR-Ranking dataset.
      

<div style="display: flex; justify-content: space-between; align-items: center;">
    <span style="margin: 0; font-weight: bold;">2022. Mar - 2023. Apr</span>
    <span style="text-align: right; font-weight: bold;">Research Intern, NExT++, NUS</span>
</div>

- Under the guidance of Prof. [Tat-Seng Chua](https://scholar.google.com/citations?user=Z9DWCBEAAAAJ&hl=zh-CN&oi=ao) and Postdoctoral Fellow [Wei Ji](https://jiwei0523.github.io/).
- Focused on information retrieval for multimodal data.

-->
         

# Publications
<span class='anchor' id='publications'></span>
please refer to [google scholar](https://scholar.google.com/citations?user=1s5SSfkAAAAJ&hl) page to check all my publications. (* Equal Contribution)


<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://arxiv.org/pdf/2407.06597" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with  Imprecise  Queries</span> 
      <br> <b>Renjie Liang</b>, Li Li, Chongzhi Zhang, Jing Wang, Xizhou Zhu, Aixin Sun
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://arxiv.org/pdf/2308.03725.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation</span> 
      <br> <b> Renjie Liang </b>, Yiming Yang, Hui Lu, Li Li
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>



<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://liziliao.github.io/papers/ACM_MM_2023_Weakly_VMR.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Partial Annotation-based Video Moment Retrieval via Iterative Learning</span> 
      <br>Wei Ji, <b>Renjie Liang</b>, Lizi Liao, Hao Fei, Fuli Feng
    <br>ACM MM 2023&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Are_Binary_Annotations_Sufficient_Video_Moment_Retrieval_via_Hierarchical_Uncertainty-Based_CVPR_2023_paper.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Are Binary Annotations Sufficient? Video Moment Retrieval via Hierarchical Uncertainty-based Active Learning</span> 
      <br> Wei Ji, <b>Renjie Liang</b>, Zhedong Zheng, Wenqiao Zhang, Shengyu Zhang, Juncheng Li, Mengze Li, Tat-Seng Chua
    <br>CVPR 2023&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<!--
# Honors and Awards
-->

# Services
<span class='anchor' id='services'></span>
Program Committee Member of ACM MM (2023) .


<br>
<br>
