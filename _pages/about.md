---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

# About Me
<span class='anchor' id='about-me'></span>

Hi! I currently serve as a research associate at **Nanyang Technological University**, working with Prof. [Aixin Sun](https://scholar.google.com/citations?user=wyKGVKUAAAAJ&hl=zh-CN). I earned my Master's degree from **National University of Singapore** in 2024, where I contributed as a research intern under the guidance of Prof. [Tat-Seng Chua](https://scholar.google.com/citations?user=Z9DWCBEAAAAJ&hl=zh-CN&oi=ao) and Prof. [Roger Zimmermann](https://scholar.google.com/citations?user=IDREwXEAAAAJ&hl=zh-CN&oi=ao). Prior to that, I successfully completed my Bachelor's degree at **TongJi University**, China in 2022.
My research interests are centered around LLM for code, multimodal understanding, and information retrieval.

# Work Experiences
<span class='anchor' id='work-experiences'></span>
Research Intern, School of Software Engineering, TongJi University.      

<div style="text-align: right;">
08/2020-06/2022
<br/>
Prof. Yan Liu
</div>



Mainly focus on neural code search and neural code completion.

---

Research Intern, NUS Centre for Extreme Search (NExT++), NUS.  
         
<div style="text-align: right;">
06/2022-02/2024
<br/>
Prof. Tat-Seng Chua
</div>



Mainly focus on multimodal fusion and understanding.

---

Research Associate, S-Lab, NTU.  

<div style="text-align: right;">
02/2024-present
<br/>
Prof. Aixin Sun
</div>



Mainly focus on data mining and information retrieval.
         


# Publications
<span class='anchor' id='publications'></span>
please refer to [google scholar](https://scholar.google.com/citations?user=r4kIL4cAAAAJ&hl=zh-CN) page to check all my publications.

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://arxiv.org/pdf/2406.01601" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Backpropogation-Free Multi-modal On-Device Model Adaptation via Cloud-Device Collaboration</span> 
      <br>Wei Ji*, <b>Li Li</b>*, Zheqi Lv*, Wenqiao Zhang, Mengze Li, Zhen Wan, Wenqiang Lei, Roger Zimmermann
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://arxiv.org/pdf/2309.17205.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Towards Complex-query Referring Image Segmentation: A Novel Benchmark</span> 
      <br>Wei Ji, <b>Li Li</b>, Hao Fei, Xiangyan Liu, Xun Yang, Juncheng Li, Roger Zimmermann
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://arxiv.org/pdf/2308.09412.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Causal SAR ATR with Limited Data via Dual Invariance</span> 
      <br>Chenwei Wang, You Qin, <b>Li Li</b>, Siyi Luo, Yulin Huang, Jifang Pei, Yin Zhang, Jianyu Yang
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://arxiv.org/pdf/2308.03725.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation</span> 
      <br>Renjie Liang, Yiming Yang, Hui Lu, <b>Li Li</b>
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/28098/28201" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Panoptic Scene Graph Generation with Semantics-prototype Learning</span> 
      <br><b>Li Li</b>, Wei Ji, Yiming Wu, Mengze Li, You Qin, Lina Wei, Roger Zimmermann
    <br>AAAI 2024&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10447193" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Domain-wise Invariant Learning for Panoptic Scene Graph Generation</span> 
      <br><b>Li Li</b>, You Qin, Wei Ji, Yuxiao Zhou, Roger Zimmermann
    <br>ICASSP 2024&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://dl.acm.org/doi/pdf/10.1145/3581783.3611847" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Biased-Predicate Annotation Identification via Unbiased Visual Predicate Representation</span> 
      <br><b>Li Li</b>*, Chenwei Wang*, You Qin, Wei Ji, Renjie Liang
    <br>ACM MM 2023&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/407106f4b56040b2e8dcad75a6e461e5-Paper-Conference.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">VPGTrans: Transfer Visual Prompt Generator across LLMs</span> 
      <br>Ao Zhang, Hao Fei, Yuan Yao, Wei Ji, <b>Li Li</b>, Zhiyuan Liu, Tat-Seng Chua
    <br>NeurIPS 2023&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://arxiv.org/pdf/2202.06649.pdf" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">On the Importance of Building High-quality Training Datasets for Neural Code Search</span> 
      <br>Zhensu Sun, <b>Li Li</b>, Yan Liu, Xiaoning Du, Li Li
    <br>ICSE 2022, <span style="color: red">Nominated for distinguished paper award</span>&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>


<!-- <table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://lili0415.github.io" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Generalized Video Moment Retrieval</span> 
      <br>Wei Ji, You Qin, Qilong Wu, <b>Li Li</b>, Pengcheng Cai, Lina Wei, Roger Zimmermann
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://lili0415.github.io" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">StableSynthNet: Revolutionizing HyperNetworks for Enhanced Multi-modal Model Generalization</span> 
      <br>Wei Ji*, <b>Li Li</b>*, Zheqi Lv*, Wenqiao Zhang, Yifang Yin, Fei Wu, Roger Zimmermann
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table>

<table style="MARGIN-BOTTOM: 10px; FONT-SIZE: 13px; BORDER-COLLAPSE: collapse; TEXT-ALIGN: left; WIDTH: 98%; BACKGROUND-COLOR: #f6fbfe">
  <tbody>
  <tr>
    <td class="left" style="FONT-SIZE: 10px; TEXT-ALIGN: center; WIDTH: 60px; BACKGROUND-COLOR: #e2eff9"><a href="https://lili0415.github.io" target="_blank"><img src="./images/pdf.png" width="100" height="100"></a></td>
    <td><span class="title" style="FONT-WEIGHT: bold">Backpropogation-Free Multi-modal On-Device Model Adaptation via Cloud-Device Collaboration</span> 
      <br>Wei Ji*, <b>Li Li</b>*, Zheqi Lv*, Wenqiao Zhang, Mengze Li, Zhen Wan, Wenqiang Lei, Roger Zimmermann
    <br>Preprint&nbsp;&nbsp; 
  </td> 
  </tr>
 </tbody>
</table> -->




<!-- - **On the Importance of Building High-quality Training Datasets for Neural Code Search**

  Zhensu Sun, <span style="border-bottom:2px solid black;">**Li Li**</span>, Yan Liu, Xiaoning Du, Li Li

  **ICSE 2022, Nominated for distinguished paper award**

- **Biased-Predicate Annotation Identification via Unbiased Visual Predicate Representation**

  <span style="border-bottom:2px solid black;">**Li Li**</span>\*, Chenwei Wang*, You Qin, Wei Ji, Renjie Liang

  **ACM MM 2023, Accepted with full marks**

- **Transfer Visual Prompt Generator across LLMs**

  Ao Zhang, Hao Fei, Yuan Yao, Wei Ji, <span style="border-bottom:2px solid black;">**Li Li**</span>, Zhiyuan Liu, Tat-Seng Chua

  **NeurIPS 2023**

- **Panoptic Scene Graph Generation with Semantics-prototype Learning**

  <span style="border-bottom:2px solid black;">**Li Li**</span>, Wei Ji, Yiming Wu, Mengze Li, You Qin, Lina Wei, Roger Zimmermann

  **AAAI 2024**

- **Domain-wise Invariant Learning for Panoptic Scene Graph Generation**

  <span style="border-bottom:2px solid black;">**Li Li**</span>, You Qin, Wei Ji, Yuxiao Zhou, Roger Zimmermann
  
  **ICASSP 2024** -->

<!-- - **StableSynthNet: Revolutionizing HyperNetworks for Enhanced Multi-modal Model Generalization**

  Wei Ji\*, <span style="border-bottom:2px solid black;">**Li Li**</span>\*, Zheqi Lv, Wenqiao Zhang, Yifang Yin, Fei Wu, Roger Zimmermann

  **Submitted to CVPR 2024** -->

<!-- 
- **Towards Complex-query Referring Image Segmentation: A Novel Benchmark**

  Wei Ji, <span style="border-bottom:2px solid black;">**Li Li**</span>, Hao Fei, Xiangyan Liu, Xun Yang, Juncheng Li, Roger Zimmermann

  **Submitted to IEEE T-MM** -->

<!-- - **Backpropogation-Free On-Device Multi-Modal Model Adaptation via Cloud-Device Collaboration**

  Wei Ji*, **Li Li\***, Zheqi Lv, Wenqiao Zhang, Mengze Li, Zhen Wan, Wenqiang Lei, Roger Zimmermann

  **Submitted to ACM Web Conference 2024** -->

# Honors and Awards
<span class='anchor' id='honors-and-awards'></span>
ICSE 2022 Distinguished Paper Award Nomination.

AAAI 2024 Student Scholarship.

# Services
<span class='anchor' id='services'></span>
Program Committee Member of ACM MM (2024) .

Program Committee Member of ECCV (2024).

Program Committee Member of ACL ARR (2024).

Program Committee Member of ICLR AGI Workshop (2024).

Program Committee Member of ACM MM MMGR Workshop (2023, 2024).

Student Volunteer at ACM Web Conference (2024).

# Educations
<span class='anchor' id='educations'></span>
  Incoming

  Doctor of Philosophy in Computer Science

  University of Southern California, USA


  ---


  2022.08 - 2024.02

  Master of Science in Industry 4.0

  National University of Singapore, Singapore


  ---
  
  2018.08 - 2022.06

  Bachelor of Engineering in Software Engineering

  TongJi University, Shanghai

<!-- <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=MtgOD5bYVhrJl1tzX74CbRhUUslEFdbq-StiPxMz5Ts&cl=ffffff&w=a"></script> -->




<!-- <script>
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="https://githublili.matomo.cloud/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.async=true; g.src='https://cdn.matomo.cloud/githublili.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script> -->